{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhDiTMlENpCF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FoxrilEqxBpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wandb\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager as fm\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "wandb.login()\n",
        "import csv\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "wandb.login(key=\"17adccf08bc2dbea6a3a448facbf79a0939941e8\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-15T18:07:53.309860Z",
          "iopub.execute_input": "2024-05-15T18:07:53.310473Z",
          "iopub.status.idle": "2024-05-15T18:08:09.721761Z",
          "shell.execute_reply.started": "2024-05-15T18:07:53.310438Z",
          "shell.execute_reply": "2024-05-15T18:08:09.720973Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOf8_1sg5ANf",
        "outputId": "0ada93db-7d9d-4755-b198-6f99a8df7f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.44.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (0.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyYAML in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (69.2.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (4.25.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Bhavik More\\.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Define the language\n",
        "#Selecting Marathi language\n",
        "\n",
        "# Step 1: Create file paths for train, test, and validation data\n",
        "train_file = f\"./aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv\"\n",
        "test_file = f\"./aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv\"\n",
        "val_file = f\"./aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv\"\n",
        "\n",
        "# Step 2: Read CSV files and split data into English and Marathi columns\n",
        "english_train = pd.read_csv(train_file, header=None).iloc[:, 0]\n",
        "marathi_train = pd.read_csv(train_file, header=None).iloc[:, 1]\n",
        "english_test = pd.read_csv(test_file, header=None).iloc[:, 0]\n",
        "marathi_test = pd.read_csv(test_file, header=None).iloc[:, 1]\n",
        "english_val = pd.read_csv(val_file, header=None).iloc[:, 0]\n",
        "marathi_val = pd.read_csv(val_file, header=None).iloc[:, 1]\n",
        "\n",
        "# Step 3: Create character lists and find maximum word lengths\n",
        "# Create a set of unique characters across all words\n",
        "english_char_set = set(char for word in english_train for char in word)\n",
        "marathi_char_set = set(char for word in marathi_train for char in word)\n",
        "\n",
        "# Sort the sets to create character lists\n",
        "english_chars = sorted(english_char_set)\n",
        "marathi_chars = sorted(marathi_char_set)\n",
        "\n",
        "# Find maximum word lengths in train data\n",
        "english_max_len = max(len(word) for word in english_train)\n",
        "marathi_max_len = max(len(word) for word in marathi_train)\n",
        "\n",
        "# Find maximum word lengths from validation and test data\n",
        "english_max_len = max(english_max_len, max(len(word) for word in english_val), max(len(word) for word in english_test))\n",
        "marathi_max_len = max(marathi_max_len, max(len(word) for word in marathi_val), max(len(word) for word in marathi_test))\n",
        "\n",
        "# Step 4: Convert words to vector representations\n",
        "english_vectors = []\n",
        "marathi_vectors = []\n",
        "\n",
        "for word in english_train:\n",
        "    vector = [english_chars.index(char) + 1 if char in english_chars else 0 for char in word]\n",
        "    vector = [len(english_chars) + 1] + vector + [0] * (english_max_len - len(word) + 1)\n",
        "    english_vectors.append(vector)\n",
        "\n",
        "for word in marathi_train:\n",
        "    vector = [marathi_chars.index(char) + 1 if char in marathi_chars else 0 for char in word]\n",
        "    vector = [len(marathi_chars) + 1] + vector + [0] * (marathi_max_len - len(word) + 1)\n",
        "    marathi_vectors.append(vector)\n",
        "\n",
        "# Step 5: Create word matrices\n",
        "english_matrix = torch.tensor(english_vectors)\n",
        "marathi_matrix = torch.tensor(marathi_vectors)\n",
        "\n",
        "# Step 6: Create word matrices for validation and test data\n",
        "english_matrix_val = torch.tensor([[english_chars.index(char) + 1 if char in english_chars else 0 for char in word] + [0] * (english_max_len - len(word) + 1) + [len(english_chars) + 1] for word in english_val])\n",
        "english_matrix_test = torch.tensor([[english_chars.index(char) + 1 if char in english_chars else 0 for char in word] + [0] * (english_max_len - len(word) + 1) + [len(english_chars) + 1] for word in english_test])\n",
        "\n",
        "marathi_matrix_val = torch.tensor([[marathi_chars.index(char) + 1 if char in marathi_chars else 0 for char in word] + [0] * (marathi_max_len - len(word) + 1) + [len(marathi_chars) + 1] for word in marathi_val])\n",
        "marathi_matrix_test = torch.tensor([[marathi_chars.index(char) + 1 if char in marathi_chars else 0 for char in word] + [0] * (marathi_max_len - len(word) + 1) + [len(marathi_chars) + 1] for word in marathi_test])"
      ],
      "metadata": {
        "id": "wqitQtc0m5Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder module for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of the input vocabulary.\n",
        "        embedding_dim (int): Dimension of the embedding layer.\n",
        "        hidden_size (int): Size of the hidden state in the recurrent layer.\n",
        "        num_layers (int): Number of layers in the recurrent layer.\n",
        "        batch_size (int): Batch size for the input data.\n",
        "        dropout_prob (float): Dropout probability for regularization.\n",
        "        bidirectional (bool): Whether to use a bidirectional recurrent layer.\n",
        "        cell_type (str): Type of recurrent cell ('RNN', 'LSTM', or 'GRU').\n",
        "\n",
        "    Attributes:\n",
        "        embedding (nn.Embedding): Embedding layer for input tokens.\n",
        "        rnn (nn.RNNBase): Recurrent layer (RNN, LSTM, or GRU).\n",
        "        dropout (nn.Dropout): Dropout layer for regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, batch_size, dropout_prob, bidirectional, cell_type):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        self.rnn = self._get_rnn_layer(embedding_dim, hidden_size, num_layers, dropout_prob, bidirectional, cell_type)\n",
        "\n",
        "    def _get_rnn_layer(self, embedding_dim, hidden_size, num_layers, dropout_prob, bidirectional, cell_type):\n",
        "        \"\"\"\n",
        "        Helper function to create the appropriate recurrent layer.\n",
        "\n",
        "        Args:\n",
        "            embedding_dim (int): Dimension of the embedding layer.\n",
        "            hidden_size (int): Size of the hidden state in the recurrent layer.\n",
        "            num_layers (int): Number of layers in the recurrent layer.\n",
        "            dropout_prob (float): Dropout probability for regularization.\n",
        "            bidirectional (bool): Whether to use a bidirectional recurrent layer.\n",
        "            cell_type (str): Type of recurrent cell ('RNN', 'LSTM', or 'GRU').\n",
        "\n",
        "        Returns:\n",
        "            nn.RNNBase: Recurrent layer (RNN, LSTM, or GRU).\n",
        "        \"\"\"\n",
        "        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n",
        "        return rnn_class(embedding_dim, hidden_size, num_layers, dropout=dropout_prob, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        \"\"\"\n",
        "        Forward pass of the Encoder module.\n",
        "\n",
        "        Args:\n",
        "            input_sequence (torch.Tensor): Input sequence of token indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output sequence of hidden states.\n",
        "            torch.Tensor: Final hidden state(s) of the recurrent layer.\n",
        "            torch.Tensor: Final cell state(s) of the recurrent layer (for LSTM only).\n",
        "        \"\"\"\n",
        "        embedded = self.dropout(self.embedding(input_sequence))\n",
        "        outputs, hidden_states = self.rnn(embedded)\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            return outputs, hidden_states[0], hidden_states[1]\n",
        "        else:\n",
        "            return outputs, hidden_states\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        \"\"\"\n",
        "        Initialize the hidden state(s) of the recurrent layer.\n",
        "\n",
        "        Args:\n",
        "            device (torch.device): Device to create the hidden state(s) on.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Initial hidden state(s) of the recurrent layer.\n",
        "            torch.Tensor: Initial cell state(s) of the recurrent layer (for LSTM only).\n",
        "        \"\"\"\n",
        "        batch_size = self.batch_size\n",
        "        hidden_size = self.hidden_size\n",
        "        num_layers = self.num_layers\n",
        "        bidirectional = self.bidirectional\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        hidden_state = torch.zeros(num_layers * num_directions, batch_size, hidden_size, device=device)\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            cell_state = torch.zeros(num_layers * num_directions, batch_size, hidden_size, device=device)\n",
        "            return hidden_state, cell_state\n",
        "        else:\n",
        "            return hidden_state"
      ],
      "metadata": {
        "id": "MET5ggfFnpU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_layer_size, output_size, decoder_layers, dropout_prob, cell_type, use_attention=False, is_bidirectional=False):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.output_size = output_size\n",
        "        self.decoder_layers = decoder_layers\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.cell_type = cell_type\n",
        "        self.use_attention = use_attention\n",
        "        self.is_bidirectional = is_bidirectional\n",
        "        self.max_length = len(english_matrix[0])\n",
        "        self.attention_weights = 0\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        rnn_input_size = hidden_layer_size if use_attention else embedding_size\n",
        "        rnn_class = self.get_rnn_class(cell_type)\n",
        "        self.rnn = rnn_class(rnn_input_size, hidden_layer_size, decoder_layers, dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "        if use_attention:\n",
        "            self.attn = nn.Linear(hidden_layer_size + embedding_size, self.max_length)\n",
        "            self.attn_combine = self.get_attention_combine_layer(hidden_layer_size, embedding_size, is_bidirectional)\n",
        "\n",
        "    def get_rnn_class(self, cell_type):\n",
        "        if cell_type == \"RNN\":\n",
        "            return nn.RNN\n",
        "        elif cell_type == \"LSTM\":\n",
        "            return nn.LSTM\n",
        "        else:\n",
        "            return nn.GRU\n",
        "\n",
        "    def get_attention_combine_layer(self, hidden_layer_size, embedding_size, is_bidirectional):\n",
        "        if is_bidirectional:\n",
        "            return nn.Linear(hidden_layer_size * 2 + embedding_size, hidden_layer_size)\n",
        "        else:\n",
        "            return nn.Linear(hidden_layer_size + embedding_size, hidden_layer_size)\n",
        "\n",
        "    def forward(self, input_seq, encoder_outputs, hidden_state, cell_state=None):\n",
        "        input_seq = input_seq.unsqueeze(0)\n",
        "        embedded = self.embedding(input_seq)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        if self.use_attention:\n",
        "            attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden_state[0]), 1)), dim=1)\n",
        "            self.attention_weights = attn_weights  # Store attention weights\n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs.permute(1, 0, 2)).squeeze(1)\n",
        "            combined_input = torch.cat((embedded[0], attn_applied), 1)\n",
        "            combined_input = self.attn_combine(combined_input).unsqueeze(0)\n",
        "            combined_input = F.relu(combined_input)\n",
        "        else:\n",
        "            combined_input = embedded\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            outputs, (hidden_state, cell_state) = self.rnn(combined_input, (hidden_state, cell_state))\n",
        "        else:\n",
        "            outputs, hidden_state = self.rnn(combined_input, hidden_state)\n",
        "\n",
        "        predictions, hidden_state, cell_state = self.generate_predictions(outputs, hidden_state, cell_state)\n",
        "\n",
        "        return predictions, hidden_state, cell_state\n",
        "\n",
        "    def generate_predictions(self, rnn_outputs, rnn_hidden_state, rnn_cell_state=None):\n",
        "        output_predictions = self.fc(rnn_outputs)\n",
        "        output_predictions = output_predictions.squeeze(0)\n",
        "\n",
        "        return (output_predictions, rnn_hidden_state, rnn_cell_state) if self.cell_type == \"LSTM\" else (output_predictions, rnn_hidden_state, rnn_cell_state)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_layer_size, device=device)\n"
      ],
      "metadata": {
        "id": "jeF9JcYvuzd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, output_size, cell_type, bidirectional, enc_lyr, dec_lyr, encoder, decoder,attention):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional = bidirectional\n",
        "        self.enc_lyr = enc_lyr\n",
        "        self.dec_lyr = dec_lyr\n",
        "        self.encoder = encoder\n",
        "        self.attention=attention\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target , teacher_force_ratio=0.5):\n",
        "        target_len = target.shape[0]\n",
        "        batch_size = source.shape[1]\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, self.output_size).to(source.device)\n",
        "\n",
        "        encoder_output, hidden, cell = self.encode_sequence(source)\n",
        "        hidden, cell = self.prepare_decoder_states(hidden, cell)\n",
        "        outputs,attentions = self.decode_sequence(target, encoder_output, hidden, cell, teacher_force_ratio)\n",
        "\n",
        "        return outputs,attentions\n",
        "\n",
        "    def encode_sequence(self, source):\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            encoder_output, hidden, cell = self.encoder(source)\n",
        "            return encoder_output, hidden, cell\n",
        "        else:\n",
        "            encoder_output, hidden = self.encoder(source)\n",
        "            return encoder_output, hidden, None\n",
        "\n",
        "    def prepare_decoder_states(self, hidden, cell):\n",
        "        if self.bidirectional or self.enc_lyr != self.dec_lyr:\n",
        "          hidden = hidden[self.enc_lyr - 1] + hidden[self.enc_lyr - 1]\n",
        "          hidden = hidden.repeat(self.dec_lyr,1,1)\n",
        "          if(self.cell_type == \"LSTM\"):\n",
        "              cell = cell[self.enc_lyr - 1] + cell[self.enc_lyr - 1]\n",
        "              cell = cell.repeat(self.dec_lyr,1,1)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "    def decode_sequence(self, tgt, enc_out, hid, cell, teacher_force_ratio):\n",
        "      batch_size = tgt.shape[1]\n",
        "      target_len = tgt.shape[0]\n",
        "      outputs = torch.zeros(target_len, batch_size, self.output_size).to(enc_out.device)\n",
        "      attentions = []\n",
        "\n",
        "      timestep = 1\n",
        "      current_token = tgt[0]\n",
        "\n",
        "      while timestep < target_len:\n",
        "          if self.cell_type == \"LSTM\":\n",
        "              output, hid, cell = self.decoder(current_token, enc_out, hid, cell)\n",
        "          else:\n",
        "              output, hid, cell = self.decoder(current_token, enc_out, hid)\n",
        "          outputs[timestep] = output\n",
        "\n",
        "          if(self.attention==True):\n",
        "            # attentions.append(self.decoder.attn_weights.detach().cpu().numpy())\n",
        "            attentions.append(self.decoder.attention_weights.detach().cpu().numpy())\n",
        "\n",
        "          if random.random() < teacher_force_ratio:\n",
        "              current_token = tgt[timestep] if timestep < target_len - 1 else output.argmax(1)\n",
        "          else:\n",
        "              current_token = output.argmax(1)\n",
        "\n",
        "          timestep += 1\n",
        "\n",
        "      attentions = np.array(attentions)\n",
        "      return outputs, attentions\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.169865Z",
          "iopub.execute_input": "2024-05-15T18:27:03.170465Z",
          "iopub.status.idle": "2024-05-15T18:27:03.186753Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.170438Z",
          "shell.execute_reply": "2024-05-15T18:27:03.185673Z"
        },
        "trusted": true,
        "id": "hrxfyWX-5ANu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sweep configuration\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'Val_Accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [ 10]},\n",
        "        \"lr\": {\"values\": [1e-4]},\n",
        "        \"cell_type\": {\"values\": [\"RNN\",\"LSTM\", \"GRU\"]},\n",
        "        \"bidirectional\": {\"values\": [True, False]},\n",
        "        \"enc_lyr\": {\"values\": [1,2]},\n",
        "        \"dec_lyr\": {\"values\": [1,2]},\n",
        "        \"batch_size\": {\"values\": [128]},\n",
        "        \"embedding_dim\": {\"values\": [32,64]},\n",
        "        \"hidden_lyr\": {\"values\": [128,256]},\n",
        "        \"encoder_dropout\": {\"values\": [0, 0.1]},\n",
        "        \"decoder_dropout\": {\"values\": [0, 0.1]},\n",
        "        \"attention\": {\"values\": [True]}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.261709Z",
          "iopub.execute_input": "2024-05-15T18:27:03.261993Z",
          "iopub.status.idle": "2024-05-15T18:27:03.272850Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.261966Z",
          "shell.execute_reply": "2024-05-15T18:27:03.271823Z"
        },
        "trusted": true,
        "id": "Y0iLw7Qp5ANw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Initialize wandb\n",
        "    wandb.init()\n",
        "    config = wandb.config\n",
        "    wandb.run.name = \"_\".join([f\"{param}:{value}\" for param, value in config.items()])\n",
        "    train_model(**config)\n",
        "\n",
        "# Initialize the sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DLA3\",entity=\"ch22m009\")\n",
        "\n",
        "# Run the sweep\n",
        "wandb.agent(sweep_id, function=main,count=50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.274089Z",
          "iopub.execute_input": "2024-05-15T18:27:03.274450Z",
          "iopub.status.idle": "2024-05-15T18:53:25.097286Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.274419Z",
          "shell.execute_reply": "2024-05-15T18:53:25.096449Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2JOjlzae5ANw",
        "outputId": "a4f8daee-b513-45e5-eaf8-bfe932c15f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: a9p0xem2\n",
            "Sweep URL: https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Agent Starting Run: ywf4novg with config:\n",
            "wandb: \tattention: True\n",
            "wandb: \tbatch_size: 128\n",
            "wandb: \tbidirectional: True\n",
            "wandb: \tcell_type: RNN\n",
            "wandb: \tdec_lyr: 2\n",
            "wandb: \tdecoder_dropout: 0\n",
            "wandb: \tembedding_dim: 32\n",
            "wandb: \tenc_lyr: 2\n",
            "wandb: \tencoder_dropout: 0\n",
            "wandb: \tepochs: 10\n",
            "wandb: \thidden_lyr: 128\n",
            "wandb: \tlr: 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.17.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\Bhavik More\\Desktop\\New1folder\\wandb\\run-20240517_195106-ywf4novg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ch22m009/DLA3/runs/ywf4novg' target=\"_blank\">fluent-sweep-1</a></strong> to <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">https://wandb.ai/ch22m009/DLA3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ch22m009/DLA3/runs/ywf4novg' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/runs/ywf4novg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                                                          | 0/400 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fluent-sweep-1</strong> at: <a href='https://wandb.ai/ch22m009/DLA3/runs/ywf4novg' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/runs/ywf4novg</a><br/> View project at: <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">https://wandb.ai/ch22m009/DLA3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240517_195106-ywf4novg\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run ywf4novg errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 308, in _run_job\n",
            "    self._function()\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\660904229.py\", line 6, in main\n",
            "    train_model(**config)\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\402864477.py\", line 35, in train_model\n",
            "    output, attentions = model(inp_data.T, target)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 21, in forward\n",
            "    output_tensor, attention_weights = self.perform_decoding(target_seq, encoder_output, hidden_state, cell_state, teacher_forcing_ratio)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 58, in perform_decoding\n",
            "    output, hidden_state = self.decoder(current_token, encoder_output, hidden_state)\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: too many values to unpack (expected 2)\n",
            "\n",
            "wandb: ERROR Run ywf4novg errored:\n",
            "wandb: ERROR Traceback (most recent call last):\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 308, in _run_job\n",
            "wandb: ERROR     self._function()\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\660904229.py\", line 6, in main\n",
            "wandb: ERROR     train_model(**config)\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\402864477.py\", line 35, in train_model\n",
            "wandb: ERROR     output, attentions = model(inp_data.T, target)\n",
            "wandb: ERROR                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "wandb: ERROR     return self._call_impl(*args, **kwargs)\n",
            "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "wandb: ERROR     return forward_call(*args, **kwargs)\n",
            "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 21, in forward\n",
            "wandb: ERROR     output_tensor, attention_weights = self.perform_decoding(target_seq, encoder_output, hidden_state, cell_state, teacher_forcing_ratio)\n",
            "wandb: ERROR                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 58, in perform_decoding\n",
            "wandb: ERROR     output, hidden_state = self.decoder(current_token, encoder_output, hidden_state)\n",
            "wandb: ERROR     ^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR ValueError: too many values to unpack (expected 2)\n",
            "wandb: ERROR \n",
            "wandb: Agent Starting Run: 3cnu2cpb with config:\n",
            "wandb: \tattention: True\n",
            "wandb: \tbatch_size: 128\n",
            "wandb: \tbidirectional: False\n",
            "wandb: \tcell_type: GRU\n",
            "wandb: \tdec_lyr: 2\n",
            "wandb: \tdecoder_dropout: 0\n",
            "wandb: \tembedding_dim: 64\n",
            "wandb: \tenc_lyr: 1\n",
            "wandb: \tencoder_dropout: 0.1\n",
            "wandb: \tepochs: 10\n",
            "wandb: \thidden_lyr: 128\n",
            "wandb: \tlr: 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.17.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\Bhavik More\\Desktop\\New1folder\\wandb\\run-20240517_195122-3cnu2cpb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ch22m009/DLA3/runs/3cnu2cpb' target=\"_blank\">earthy-sweep-2</a></strong> to <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">https://wandb.ai/ch22m009/DLA3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ch22m009/DLA3/runs/3cnu2cpb' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/runs/3cnu2cpb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                                                          | 0/400 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earthy-sweep-2</strong> at: <a href='https://wandb.ai/ch22m009/DLA3/runs/3cnu2cpb' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/runs/3cnu2cpb</a><br/> View project at: <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">https://wandb.ai/ch22m009/DLA3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240517_195122-3cnu2cpb\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run 3cnu2cpb errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 308, in _run_job\n",
            "    self._function()\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\660904229.py\", line 6, in main\n",
            "    train_model(**config)\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\402864477.py\", line 35, in train_model\n",
            "    output, attentions = model(inp_data.T, target)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 21, in forward\n",
            "    output_tensor, attention_weights = self.perform_decoding(target_seq, encoder_output, hidden_state, cell_state, teacher_forcing_ratio)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 58, in perform_decoding\n",
            "    output, hidden_state = self.decoder(current_token, encoder_output, hidden_state)\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: too many values to unpack (expected 2)\n",
            "\n",
            "wandb: ERROR Run 3cnu2cpb errored:\n",
            "wandb: ERROR Traceback (most recent call last):\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 308, in _run_job\n",
            "wandb: ERROR     self._function()\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\660904229.py\", line 6, in main\n",
            "wandb: ERROR     train_model(**config)\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\402864477.py\", line 35, in train_model\n",
            "wandb: ERROR     output, attentions = model(inp_data.T, target)\n",
            "wandb: ERROR                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "wandb: ERROR     return self._call_impl(*args, **kwargs)\n",
            "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "wandb: ERROR     return forward_call(*args, **kwargs)\n",
            "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 21, in forward\n",
            "wandb: ERROR     output_tensor, attention_weights = self.perform_decoding(target_seq, encoder_output, hidden_state, cell_state, teacher_forcing_ratio)\n",
            "wandb: ERROR                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 58, in perform_decoding\n",
            "wandb: ERROR     output, hidden_state = self.decoder(current_token, encoder_output, hidden_state)\n",
            "wandb: ERROR     ^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR ValueError: too many values to unpack (expected 2)\n",
            "wandb: ERROR \n",
            "wandb: Agent Starting Run: zbqa0c9e with config:\n",
            "wandb: \tattention: True\n",
            "wandb: \tbatch_size: 128\n",
            "wandb: \tbidirectional: True\n",
            "wandb: \tcell_type: GRU\n",
            "wandb: \tdec_lyr: 1\n",
            "wandb: \tdecoder_dropout: 0.1\n",
            "wandb: \tembedding_dim: 32\n",
            "wandb: \tenc_lyr: 1\n",
            "wandb: \tencoder_dropout: 0\n",
            "wandb: \tepochs: 10\n",
            "wandb: \thidden_lyr: 256\n",
            "wandb: \tlr: 0.0001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.17.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\Bhavik More\\Desktop\\New1folder\\wandb\\run-20240517_195139-zbqa0c9e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ch22m009/DLA3/runs/zbqa0c9e' target=\"_blank\">woven-sweep-3</a></strong> to <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">https://wandb.ai/ch22m009/DLA3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/sweeps/a9p0xem2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ch22m009/DLA3/runs/zbqa0c9e' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/runs/zbqa0c9e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|                                                                                          | 0/400 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">woven-sweep-3</strong> at: <a href='https://wandb.ai/ch22m009/DLA3/runs/zbqa0c9e' target=\"_blank\">https://wandb.ai/ch22m009/DLA3/runs/zbqa0c9e</a><br/> View project at: <a href='https://wandb.ai/ch22m009/DLA3' target=\"_blank\">https://wandb.ai/ch22m009/DLA3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240517_195139-zbqa0c9e\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run zbqa0c9e errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 308, in _run_job\n",
            "    self._function()\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\660904229.py\", line 6, in main\n",
            "    train_model(**config)\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\402864477.py\", line 35, in train_model\n",
            "    output, attentions = model(inp_data.T, target)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 21, in forward\n",
            "    output_tensor, attention_weights = self.perform_decoding(target_seq, encoder_output, hidden_state, cell_state, teacher_forcing_ratio)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 58, in perform_decoding\n",
            "    output, hidden_state = self.decoder(current_token, encoder_output, hidden_state)\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: too many values to unpack (expected 2)\n",
            "\n",
            "wandb: ERROR Run zbqa0c9e errored:\n",
            "wandb: ERROR Traceback (most recent call last):\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\agents\\pyagent.py\", line 308, in _run_job\n",
            "wandb: ERROR     self._function()\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\660904229.py\", line 6, in main\n",
            "wandb: ERROR     train_model(**config)\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\402864477.py\", line 35, in train_model\n",
            "wandb: ERROR     output, attentions = model(inp_data.T, target)\n",
            "wandb: ERROR                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
            "wandb: ERROR     return self._call_impl(*args, **kwargs)\n",
            "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
            "wandb: ERROR     return forward_call(*args, **kwargs)\n",
            "wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 21, in forward\n",
            "wandb: ERROR     output_tensor, attention_weights = self.perform_decoding(target_seq, encoder_output, hidden_state, cell_state, teacher_forcing_ratio)\n",
            "wandb: ERROR                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR   File \"C:\\Users\\Bhavik More\\AppData\\Local\\Temp\\ipykernel_29744\\1358276507.py\", line 58, in perform_decoding\n",
            "wandb: ERROR     output, hidden_state = self.decoder(current_token, encoder_output, hidden_state)\n",
            "wandb: ERROR     ^^^^^^^^^^^^^^^^^^^^\n",
            "wandb: ERROR ValueError: too many values to unpack (expected 2)\n",
            "wandb: ERROR \n",
            "Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "wandb: ERROR Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "wandb: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihtWfQYN5ANw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
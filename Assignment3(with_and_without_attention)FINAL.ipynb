{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhDiTMlENpCF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FoxrilEqxBpt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager as fm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "# Additional setup\n",
        "wandb.login()\n",
        "wandb.login(key=\"8f58df9a66485e9ea9149b8b599cb14eb71832dc\")\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-15T18:07:53.309860Z",
          "iopub.execute_input": "2024-05-15T18:07:53.310473Z",
          "iopub.status.idle": "2024-05-15T18:08:09.721761Z",
          "shell.execute_reply.started": "2024-05-15T18:07:53.310438Z",
          "shell.execute_reply": "2024-05-15T18:08:09.720973Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOf8_1sg5ANf",
        "outputId": "847b8e54-e8a1-4162-f522-144dc7ee92b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.44.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (69.2.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wandb) (4.25.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\bhavik more\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Currently logged in as: bhavik-160990105023. Use `wandb login --relogin` to force relogin\n",
            "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Bhavik More\\.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Define the language\n",
        "#Selecting Marathi language\n",
        "\n",
        "# Step 1: Create file paths for train, test, and validation data\n",
        "train_file = f\"./aksharantar_sampled/aksharantar_sampled/mar/mar_train.csv\"\n",
        "test_file = f\"./aksharantar_sampled/aksharantar_sampled/mar/mar_test.csv\"\n",
        "val_file = f\"./aksharantar_sampled/aksharantar_sampled/mar/mar_valid.csv\"\n",
        "\n",
        "# Step 2: Read CSV files and split data into English and Marathi columns\n",
        "english_train = pd.read_csv(train_file, header=None).iloc[:, 0]\n",
        "marathi_train = pd.read_csv(train_file, header=None).iloc[:, 1]\n",
        "english_test = pd.read_csv(test_file, header=None).iloc[:, 0]\n",
        "marathi_test = pd.read_csv(test_file, header=None).iloc[:, 1]\n",
        "english_val = pd.read_csv(val_file, header=None).iloc[:, 0]\n",
        "marathi_val = pd.read_csv(val_file, header=None).iloc[:, 1]\n",
        "\n",
        "# Step 3: Create character lists and find maximum word lengths\n",
        "# Create a set of unique characters across all words\n",
        "english_char_set = set(char for word in english_train for char in word)\n",
        "marathi_char_set = set(char for word in marathi_train for char in word)\n",
        "\n",
        "# Sort the sets to create character lists\n",
        "english_chars = sorted(english_char_set)\n",
        "marathi_chars = sorted(marathi_char_set)\n",
        "\n",
        "# Find maximum word lengths in train data\n",
        "english_max_len = max(len(word) for word in english_train)\n",
        "marathi_max_len = max(len(word) for word in marathi_train)\n",
        "\n",
        "# Find maximum word lengths from validation and test data\n",
        "english_max_len = max(english_max_len, max(len(word) for word in english_val), max(len(word) for word in english_test))\n",
        "marathi_max_len = max(marathi_max_len, max(len(word) for word in marathi_val), max(len(word) for word in marathi_test))\n",
        "\n",
        "# Step 4: Convert words to vector representations\n",
        "english_vectors = []\n",
        "marathi_vectors = []\n",
        "\n",
        "for word in english_train:\n",
        "    vector = [english_chars.index(char) + 1 if char in english_chars else 0 for char in word]\n",
        "    vector = [len(english_chars) + 1] + vector + [0] * (english_max_len - len(word) + 1)\n",
        "    english_vectors.append(vector)\n",
        "\n",
        "for word in marathi_train:\n",
        "    vector = [marathi_chars.index(char) + 1 if char in marathi_chars else 0 for char in word]\n",
        "    vector = [len(marathi_chars) + 1] + vector + [0] * (marathi_max_len - len(word) + 1)\n",
        "    marathi_vectors.append(vector)\n",
        "\n",
        "# Step 5: Create word matrices\n",
        "english_matrix = torch.tensor(english_vectors)\n",
        "marathi_matrix = torch.tensor(marathi_vectors)\n",
        "\n",
        "# Step 6: Create word matrices for validation and test data\n",
        "english_matrix_val = torch.tensor([[english_chars.index(char) + 1 if char in english_chars else 0 for char in word] + [0] * (english_max_len - len(word) + 1) + [len(english_chars) + 1] for word in english_val])\n",
        "english_matrix_test = torch.tensor([[english_chars.index(char) + 1 if char in english_chars else 0 for char in word] + [0] * (english_max_len - len(word) + 1) + [len(english_chars) + 1] for word in english_test])\n",
        "\n",
        "marathi_matrix_val = torch.tensor([[marathi_chars.index(char) + 1 if char in marathi_chars else 0 for char in word] + [0] * (marathi_max_len - len(word) + 1) + [len(marathi_chars) + 1] for word in marathi_val])\n",
        "marathi_matrix_test = torch.tensor([[marathi_chars.index(char) + 1 if char in marathi_chars else 0 for char in word] + [0] * (marathi_max_len - len(word) + 1) + [len(marathi_chars) + 1] for word in marathi_test])"
      ],
      "metadata": {
        "id": "YTxO7XGd6fVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder module for sequence-to-sequence models.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of the input vocabulary.\n",
        "        embedding_dim (int): Dimension of the embedding layer.\n",
        "        hidden_size (int): Size of the hidden state in the recurrent layer.\n",
        "        num_layers (int): Number of layers in the recurrent layer.\n",
        "        batch_size (int): Batch size for the input data.\n",
        "        dropout_prob (float): Dropout probability for regularization.\n",
        "        bidirectional (bool): Whether to use a bidirectional recurrent layer.\n",
        "        cell_type (str): Type of recurrent cell ('RNN', 'LSTM', or 'GRU').\n",
        "\n",
        "    Attributes:\n",
        "        embedding (nn.Embedding): Embedding layer for input tokens.\n",
        "        rnn (nn.RNNBase): Recurrent layer (RNN, LSTM, or GRU).\n",
        "        dropout (nn.Dropout): Dropout layer for regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, batch_size, dropout_prob, bidirectional, cell_type):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.bidirectional = bidirectional\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        self.rnn = self._get_rnn_layer(embedding_dim, hidden_size, num_layers, dropout_prob, bidirectional, cell_type)\n",
        "\n",
        "    def _get_rnn_layer(self, embedding_dim, hidden_size, num_layers, dropout_prob, bidirectional, cell_type):\n",
        "        \"\"\"\n",
        "        Helper function to create the appropriate recurrent layer.\n",
        "\n",
        "        Args:\n",
        "            embedding_dim (int): Dimension of the embedding layer.\n",
        "            hidden_size (int): Size of the hidden state in the recurrent layer.\n",
        "            num_layers (int): Number of layers in the recurrent layer.\n",
        "            dropout_prob (float): Dropout probability for regularization.\n",
        "            bidirectional (bool): Whether to use a bidirectional recurrent layer.\n",
        "            cell_type (str): Type of recurrent cell ('RNN', 'LSTM', or 'GRU').\n",
        "\n",
        "        Returns:\n",
        "            nn.RNNBase: Recurrent layer (RNN, LSTM, or GRU).\n",
        "        \"\"\"\n",
        "        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n",
        "        return rnn_class(embedding_dim, hidden_size, num_layers, dropout=dropout_prob, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, input_sequence):\n",
        "        \"\"\"\n",
        "        Forward pass of the Encoder module.\n",
        "\n",
        "        Args:\n",
        "            input_sequence (torch.Tensor): Input sequence of token indices.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output sequence of hidden states.\n",
        "            torch.Tensor: Final hidden state(s) of the recurrent layer.\n",
        "            torch.Tensor: Final cell state(s) of the recurrent layer (for LSTM only).\n",
        "        \"\"\"\n",
        "        embedded = self.dropout(self.embedding(input_sequence))\n",
        "        outputs, hidden_states = self.rnn(embedded)\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            return outputs, hidden_states[0], hidden_states[1]\n",
        "        else:\n",
        "            return outputs, hidden_states\n",
        "\n",
        "    def initialize_hidden_state(self, device):\n",
        "        \"\"\"\n",
        "        Initialize the hidden state(s) of the recurrent layer.\n",
        "\n",
        "        Args:\n",
        "            device (torch.device): Device to create the hidden state(s) on.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Initial hidden state(s) of the recurrent layer.\n",
        "            torch.Tensor: Initial cell state(s) of the recurrent layer (for LSTM only).\n",
        "        \"\"\"\n",
        "        batch_size = self.batch_size\n",
        "        hidden_size = self.hidden_size\n",
        "        num_layers = self.num_layers\n",
        "        bidirectional = self.bidirectional\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        hidden_state = torch.zeros(num_layers * num_directions, batch_size, hidden_size, device=device)\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            cell_state = torch.zeros(num_layers * num_directions, batch_size, hidden_size, device=device)\n",
        "            return hidden_state, cell_state\n",
        "        else:\n",
        "            return hidden_state"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.136453Z",
          "iopub.execute_input": "2024-05-15T18:27:03.136747Z",
          "iopub.status.idle": "2024-05-15T18:27:03.147321Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.136721Z",
          "shell.execute_reply": "2024-05-15T18:27:03.145892Z"
        },
        "trusted": true,
        "id": "cCvPKmZz5ANt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.148604Z",
          "iopub.execute_input": "2024-05-15T18:27:03.148950Z",
          "iopub.status.idle": "2024-05-15T18:27:03.167210Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.148917Z",
          "shell.execute_reply": "2024-05-15T18:27:03.166171Z"
        },
        "trusted": true,
        "id": "TXB4oVpF5ANu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout, cell_type, attention=False, bidirectional=False):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type\n",
        "        self.attention = attention\n",
        "        self.bidirectional = bidirectional\n",
        "        self.max_length = len(english_matrix[0])\n",
        "        self.attn_weights = 0\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        rnn_input_size = hidden_size if attention else embedding_size\n",
        "        rnn_class = nn.RNN if cell_type == \"RNN\" else (nn.LSTM if cell_type == \"LSTM\" else nn.GRU)\n",
        "        self.rnn = rnn_class(rnn_input_size, hidden_size, num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        if attention:\n",
        "            self.attn = nn.Linear(hidden_size + embedding_size, self.max_length)\n",
        "            self.attn_combine = nn.Linear(hidden_size * 2 + embedding_size, hidden_size) if bidirectional else nn.Linear(hidden_size + embedding_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, output, hidden, cell=None):\n",
        "        x = x.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "\n",
        "        if self.attention:\n",
        "            attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "            self.attn_weights = attn_weights  # Store attention weights\n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(1), output.permute(1, 0, 2)).squeeze(1)\n",
        "            op = torch.cat((embedded[0], attn_applied), 1)\n",
        "            op = self.attn_combine(op).unsqueeze(0)\n",
        "            op = F.relu(op)\n",
        "        else:\n",
        "            op = embedded\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            outputs, (hidden, cell) = self.rnn(op, (hidden, cell))\n",
        "        else:\n",
        "            outputs, hidden = self.rnn(op, hidden)\n",
        "\n",
        "        output_predictions = self.fc(outputs)\n",
        "        output_predictions = output_predictions.squeeze(0)\n",
        "\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            return output_predictions, hidden, cell\n",
        "        else:\n",
        "            return output_predictions, hidden, None\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "jLS0REmZLsEv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.169865Z",
          "iopub.execute_input": "2024-05-15T18:27:03.170465Z",
          "iopub.status.idle": "2024-05-15T18:27:03.186753Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.170438Z",
          "shell.execute_reply": "2024-05-15T18:27:03.185673Z"
        },
        "trusted": true,
        "id": "hrxfyWX-5ANu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#working with original decoder\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, output_size, cell_type, bidirectional, enc_lyr, dec_lyr, encoder, decoder, attention):\n",
        "        super(Model, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional = bidirectional\n",
        "        self.enc_lyr = enc_lyr\n",
        "        self.dec_lyr = dec_lyr\n",
        "        self.encoder = encoder\n",
        "        self.attention = attention\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        target_len = target.shape[0]\n",
        "        batch_size = source.shape[1]\n",
        "        outputs = torch.zeros(target_len, batch_size, self.output_size).to(source.device)\n",
        "\n",
        "        # Encode the source sequence\n",
        "        if self.cell_type == \"LSTM\":\n",
        "            encoder_output, hidden, cell = self.encoder(source)\n",
        "        else:\n",
        "            encoder_output, hidden = self.encoder(source)\n",
        "            cell = None\n",
        "\n",
        "        # Prepare the decoder states\n",
        "        if self.bidirectional or self.enc_lyr != self.dec_lyr:\n",
        "            hidden = hidden[self.enc_lyr - 1] + hidden[self.enc_lyr - 1]\n",
        "            hidden = hidden.repeat(self.dec_lyr, 1, 1)\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                cell = cell[self.enc_lyr - 1] + cell[self.enc_lyr - 1]\n",
        "                cell = cell.repeat(self.dec_lyr, 1, 1)\n",
        "        else:\n",
        "            hidden = hidden.repeat(self.dec_lyr, 1, 1)\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                cell = cell.repeat(self.dec_lyr, 1, 1)\n",
        "\n",
        "        # Decode the target sequence\n",
        "        attentions = []\n",
        "        timestep = 1\n",
        "        current_token = target[0]\n",
        "\n",
        "        while timestep < target_len:\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                output, hidden, cell = self.decoder(current_token, encoder_output, hidden, cell)\n",
        "            else:\n",
        "                output, hidden, cell = self.decoder(current_token, encoder_output, hidden)\n",
        "                cell = None\n",
        "\n",
        "            outputs[timestep] = output\n",
        "\n",
        "            if self.attention:\n",
        "                attentions.append(self.decoder.attn_weights.detach().cpu().numpy())\n",
        "\n",
        "            if random.random() < teacher_force_ratio:\n",
        "                current_token = target[timestep] if timestep < target_len - 1 else output.argmax(1)\n",
        "            else:\n",
        "                current_token = output.argmax(1)\n",
        "\n",
        "            timestep += 1\n",
        "\n",
        "        attentions = np.array(attentions)\n",
        "        return outputs, attentions"
      ],
      "metadata": {
        "id": "YUJZYcwd6BJf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "uhUMKk_VUoHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, lr, cell_type, bidirectional, enc_lyr, dec_lyr, batch_size, embedding_dim, hidden_lyr, encoder_dropout, decoder_dropout, attention, language=\"marathi\"):\n",
        "    pad_idx = len(marathi_chars) + 1\n",
        "    plot_heatmap = False\n",
        "    input_size_encoder = len(english_chars)\n",
        "    input_size_decoder = len(marathi_chars)\n",
        "    output_size = len(marathi_chars)\n",
        "    input_size_encoder += 2\n",
        "    input_size_decoder += 2\n",
        "    output_size += 2\n",
        "    encoder = Encoder(input_size_encoder, embedding_dim, hidden_lyr, enc_lyr, batch_size, encoder_dropout, bidirectional, cell_type).to(device)\n",
        "    decoder = Decoder(input_size_decoder, embedding_dim, hidden_lyr, output_size, dec_lyr, decoder_dropout, cell_type, attention, bidirectional).to(device)\n",
        "    model = Seq2SeqModel(output_size, cell_type, bidirectional, enc_lyr, dec_lyr, encoder, decoder, attention).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "    char_list = {\"english\": english_chars, \"marathi\": marathi_chars}[language]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch: \", epoch+1)\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        val_loss = 0\n",
        "        step = 0\n",
        "        total_batches = len(english_matrix) // batch_size\n",
        "        correct_count = 0\n",
        "        total_samples = len(english_matrix)\n",
        "\n",
        "        for batch_idx in tqdm(range(total_batches)):\n",
        "            start_idx = batch_size * batch_idx\n",
        "            end_idx = batch_size * (batch_idx + 1)\n",
        "            inp_data = english_matrix[start_idx:end_idx].to(device)\n",
        "            target = marathi_matrix[start_idx:end_idx].to(device)\n",
        "            target = target.T\n",
        "            optimizer.zero_grad()\n",
        "            output, attentions = model(inp_data.T, target)\n",
        "            output = output[1:].reshape(-1, output.shape[2])\n",
        "            target = target[1:].reshape(-1)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            predicted_tokens = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
        "            correct_count += torch.sum(predicted_tokens == target).item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_batches = len(english_matrix_val) // batch_size\n",
        "            val_correct_count = 0\n",
        "            val_total_samples = len(english_matrix_val)\n",
        "            val_predicted_words = []\n",
        "            val_attention_list = [np.random.rand(10, 10)]\n",
        "\n",
        "            for val_batch_idx in range(val_batches):\n",
        "                val_start_idx = batch_size * val_batch_idx\n",
        "                val_end_idx = batch_size * (val_batch_idx + 1)\n",
        "                val_inp_data = english_matrix_val[val_start_idx:val_end_idx].to(device)\n",
        "                val_target = marathi_matrix_val[val_start_idx:val_end_idx].to(device)\n",
        "                val_target = val_target.T\n",
        "                val_output, attentions = model(val_inp_data.T, val_target)\n",
        "                val_output = val_output[1:].reshape(-1, val_output.shape[2])\n",
        "                val_target = val_target[1:].reshape(-1)\n",
        "                val_loss += criterion(val_output, val_target).item()\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                # predicted_tokens = torch.argmax(F.softmax(val_output, dim=1), dim=1)\n",
        "                # predicted_tokens = torch.argmax(F.softmax(val_output, dim=-1), dim=-1).T\n",
        "                # predicted_tokens = torch.argmax(F.softmax(val_output, dim=1), dim=1).T\n",
        "                predicted_tokens = torch.argmax(F.softmax(val_output, dim=1), dim=1).permute(0, 2, 1)\n",
        "                val_correct_count += torch.sum(predicted_tokens == val_target).item()\n",
        "\n",
        "                # Calculate predicted words and attention list\n",
        "                if val_batch_idx == 0:\n",
        "                    val_attention_list[0] = attentions\n",
        "                predicted_tokens = torch.argmax(F.softmax(val_output, dim=2), dim=2).T\n",
        "                for tokens in predicted_tokens:\n",
        "                    predicted_word = \"\".join([char_list[i - 1] for i in tokens[1:] if i > 0])\n",
        "                    val_predicted_words.append(predicted_word)\n",
        "\n",
        "            val_loss /= val_batches\n",
        "\n",
        "            training_accuracy = (correct_count * 100) / total_samples\n",
        "            val_accuracy = (val_correct_count * 100) / val_total_samples\n",
        "\n",
        "            wandb.log({\n",
        "                \"Epoch\": epoch+1,\n",
        "                \"Loss\": total_loss / step,\n",
        "                \"Accuracy\": training_accuracy,\n",
        "                \"Val_Accuracy\": val_accuracy,\n",
        "                \"Val_Loss\": val_loss\n",
        "            })\n",
        "\n",
        "            print(f\"Loss: {total_loss/step}\\t Accuracy: {training_accuracy}\\t Val_Accuracy: {val_accuracy}\\t Val_Loss: {val_loss}\")\n",
        "\n",
        "        test_accuracy, predicted_words, attention_list = calculate_accuracy_test(model, english_matrix_test, marathi_matrix_test, batch_size, language)\n",
        "\n",
        "        wandb.log({'Test_Accuracy_Without_Attention': test_accuracy})\n",
        "        plot_attention_heatmap_grid(marathi_test[:10], predicted_words[:10], attention_list[0][:10])"
      ],
      "metadata": {
        "id": "pwj_SQjibt8n"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.240053Z",
          "iopub.execute_input": "2024-05-15T18:27:03.240346Z",
          "iopub.status.idle": "2024-05-15T18:27:03.259077Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.240322Z",
          "shell.execute_reply": "2024-05-15T18:27:03.258238Z"
        },
        "trusted": true,
        "id": "zIDoph7J5ANv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sweep configuration\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'Val_Accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\"values\": [ 5, 10 , 15]},\n",
        "        \"lr\": {\"values\": [1e-3, 1e-4]},\n",
        "        \"cell_type\": {\"values\": [\"RNN\",\"LSTM\", \"GRU\"]},\n",
        "        \"bidirectional\": {\"values\": [True, False]},\n",
        "        \"enc_lyr\": {\"values\": [1,2, 3,4]},\n",
        "        \"dec_lyr\": {\"values\": [1,2, 3,4]},\n",
        "        \"batch_size\": {\"values\": [32,64,128]},\n",
        "        \"embedding_dim\": {\"values\": [32,64,128]},\n",
        "        \"hidden_lyr\": {\"values\": [64,128,256]},\n",
        "        \"encoder_dropout\": {\"values\": [0, 0.1, 0.2]},\n",
        "        \"decoder_dropout\": {\"values\": [0, 0.1, 0.2]},\n",
        "        \"attention\": {\"values\": [False]}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.261709Z",
          "iopub.execute_input": "2024-05-15T18:27:03.261993Z",
          "iopub.status.idle": "2024-05-15T18:27:03.272850Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.261966Z",
          "shell.execute_reply": "2024-05-15T18:27:03.271823Z"
        },
        "trusted": true,
        "id": "Y0iLw7Qp5ANw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Initialize wandb\n",
        "    wandb.init()\n",
        "    config = wandb.config\n",
        "    train(**config)\n",
        "\n",
        "# Initialize the sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"test123\",entity=\"bhavik-160990105023\")\n",
        "\n",
        "# Run the sweep\n",
        "wandb.agent(sweep_id, function=main,count=50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-15T18:27:03.274089Z",
          "iopub.execute_input": "2024-05-15T18:27:03.274450Z",
          "iopub.status.idle": "2024-05-15T18:53:25.097286Z",
          "shell.execute_reply.started": "2024-05-15T18:27:03.274419Z",
          "shell.execute_reply": "2024-05-15T18:53:25.096449Z"
        },
        "trusted": true,
        "id": "2JOjlzae5ANw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihtWfQYN5ANw"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}
